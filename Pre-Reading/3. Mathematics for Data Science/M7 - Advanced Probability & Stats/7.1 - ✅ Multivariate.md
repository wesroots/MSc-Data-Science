---
Ex. Completed: false
tags:
  - maths
Links:
  - "[[3.5 - ✅ Variance & Covariance]]"
  - "[[4.2 - ✅ Random Variables]]"
---
> [!note] Topic Overview
> (Definition)
> (Why it matters)
> 

# Intro
## Definition
- Univariate -> one random variable
- Bivariate -> two random variables
- Multivariate -> more than one random variable studied jointly
	- We look at a vector of random variables at the same time:
$$
X = (X_1, X_2, ..., X_n)
$$
# Random Vectors
## Definition
An RV is a collection of random variables treated as one object
- Why group?
	- Because variables can be related (correlated), and we often care about their joint behaviour, not just one at a time
### Notation
$$
X = \begin{bmatrix} X_1\\X_2\\\vdots\\X_n \end{bmatrix}
$$
- Think of it as a vector where each entry is a random variable
- $n$ = number of variables

# Joint Distributions
## Joint PMF or PDF
A joint distribution describes the probability of two or more random variables together
### Discrete case (PMF)
For random variables $X,Y$,
$$
p(x,y) = P(X=x, Y=y)
$$
### Continuous Case (PDF)
For continuous $X,Y$,
$$
f(x,y) \geq 0, \quad \int\int f(x,y)\ dx\ dy=1
$$
- Means: integrate the joint PDF over all $x$ and all $y$, and the total probability must be 1
	- It is a double integral over both variables
- Example:
	- Joint density of height and weight
## Relationship to Marginal Distributions
- A marginal distribution is the distribution of one variable alone, obtained by summing or integrating out the others
- Intuition:
	- Joint distribution = "full picture" of all variables
	- Marginal = "one part" of the picture

# Covariance and Correlation
## Covariance
[[3.5 - ✅ Variance & Covariance]]
## Correlation vs. Independence
### Correlation
Scaled version of covariance -> always between -1 and +1
- +1 -> perfect positive linear relationship
- -1 -> perfect negative linear relationship
- 0 -> no linear relationship
### Independence
Much stronger. If $X$ and $Y$ are independent, knowing one tells you nothing about the other
- Independence $\Rightarrow$ correlation = 0

# Multivariate Normal Distribution
## Mean Vector $\mu$, Covariance Matrix $\Sigma$
- In 1D, a normal distribution is defined by mean and variance
- In multiple dimensions
	- Mean vector $\mu = (\mu_1, \mu_2, ..., \mu_n)$ -> gives the central point in $n$-dimensional space
	- Covariance matrix $\Sigma$ -> describes spread and relationships between variables
## Importance in Stats and ML
### Natural model for multivariate data
- Many real world variables are approximately normal
	- Bell-shaped, follow multivariate normal
### Foundation for stats
- A lot of statistical methods assume the data is multivariate normal
### Linear models
- E.g., regression, PCA, factor analysis
### ML
- Some algorithms are built on the idea that data is (or can be approximated by) multivariate normal
### Finance
- Asset returns are sometimes modelled this way to study risk and dependence between investments